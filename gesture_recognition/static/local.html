<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Hand Gesture Classifier</title>

    <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
    <style>
      body {font-family: "Franklin Gothic Medium", "Franklin Gothic", "ITC Franklin Gothic", Arial, sans-serif;}
      * {
          overflow: hidden; 
          margin: 0;
          outline: 0;
          padding: 0;
      }

      /* Style title */
      .title {
        text-align: center;
        padding: 25px;
      }

      /* Style login area */
      .log_form {
        position: absolute;
        padding-top: 5px;
        padding-left: 5px;
      }
      input[type=username], input[type=password] {
        position: relative;
        width: 50%;
        left: 25%;
        padding: 5px;
        margin: 5px 0;
        display: inline-block;
        border: 1px solid #ccc;
      }
      button[type=submit] {
        position: relative;
        width: 50%;
        left: 25%;
        padding: 5px;
        margin: 5px 5px;
        background-color: #1100ff;
        color: white;
        border: 1px solid #ccc;
        cursor: pointer;
      }
      label.checkbox {
        position: relative;
        left: 20%;
        padding: 5px;
        margin: 5px 5px;
      }

      /* Style left and right content */
      div.left_content {
        position: absolute;
        float: left;
        visibility: hidden;
        text-align: left;
      } 
      div.right_content {
        position: absolute;
        float: right;
        visibility: hidden;
        text-align: left;
      }
      .right_text, .left_text {
        padding-right: 40px;
        padding-left: 40px;
        position: relative;
      }
      h2 {
        text-align: center;
      }
      li{
        list-style-position: inside;
        left: 20px;
        position: relative;
      }

      /* Style video streams */
      #container {
        width: 0px;
        height: 0px;
      }
      canvas, video {
        position: absolute;
      }
      video {
        transform: scale(-1, 1);            /*For Firefox (& IE) */
        -webkit-transform: scale(-1, 1);     /*for Chrome & Opera (& Safari) */
      }

      /* Style main interface */     
      .input_and_prediction {
        position: absolute;
        visibility: hidden;
        text-align: center;
        vertical-align: top;
        padding-top: 10px;
        padding-bottom: 10px; 
        height: 185px;
      }
      .input_gest, .input_command {
        display: inline-block;
        text-align: left;
        width: 45%;
        vertical-align: top;
      }
      .input_box {
        width: 130px;
      }
      </style>
  </head>
  <body>
    <h1 class="title" id="title">Gesture Recognition by Josh Clemons</h1>

    <div class="log_form", id="log_form">
      <input id="username" type="username" placeholder="Email" name="uname" required>
      <input id="password" type="password" placeholder="Password" name="psw" required> 
      <button type="submit", id="login_button">Login to start gesture prediction</button>
      <br>
      <label class="checkbox" >
        <input type="checkbox" checked="checked" name="remember"> Remember me</input>        
      </label>
      <label class="checkbox">
        <input type="checkbox" checked="checked" name="permission"> <span title="Check this box to allow all webcam images to be saved. This will improve model training results. Only black and white images of gestures will be saved otherwise. Read disclaimer to learn more about what data is collected.">Okay to store all webcam data</span></input>
      </label>
    </div>

    <div class="left_content" id="left_content">
      <h2>What does this application do?</h2>
      <p class="left_text">This application recognizes simple hand gestures performed in front of one's webcam. Images from your webcam's video stream are downloaded, processed, and fed them into a modified version of the VGG-16 convolutional neural network. The algorithm's prediction and prediction confidence are returned beneath the "Prediction" field.</p>
      <br>
      <p class="left_text">This algorithm predicts the hand gestures listed below.</p>
      <ul class="left_text"> 
        <li>Open palm</li>
        <li>Fist</li>
        <li>Closed palm</li>
        <li>L</li>
        <li>Thumbs up</li>
      </ul>  
      <br><br><br>
      <h2 class="left_text">How do I use this application?</h2>
      <p class="left_text">To use this application, follow the steps below.</p>
        <ol class="left_text">
          <li>Permit the website access to your computer's webcam</li>
          <li>Allow the camera to record for several seconds until the image stabilizes and environment lighting becomes constant</li>
          <li>Completely step out of the camera's field of view and type "b" into the "Input key" box. This saves the current image as the "background image" that will be subtracted from all future images to isolate the presented hand gesture.</li>
          <li>Perform any one of the hand gestures listed above and see how the model performs!</li>
        </ol>  
    </div>

    <div class="right_content">
      <h2 class="right_text">What do these videos show?</h2>
      <p class="right_text">The top video shows your webcam's video stream while the bottom video shows the processed images that are fed into the neural network. This algorithm is very sensitive to changes in environment lighting, so it is important to monitor the processed images and ensure that the background remains black while only your hand and arm appear white. If this is not the case, the algorithm will be fed noisy data and may not function properly.</p> 
      <br>
      <p class="right_text">If the background appears noisy, step out of the camera's field of view and allow its lighting to restabilize. If the background still appears noisy, type "r" into the "Input" box to erase the current background image then type "b" to save a new background.</p> 
      <br>
      <p class="right_text">To pause the current frame and prediction, type "p" into the "Input" box. Type "p" again to resume predictions.</p>
      <br><br><br>
      <h2 class="right_text">Project background and contact information</h2>
      <p class="right_text">I developed and deployed this gesture recognition application to satisfy the capstone project requirement for my Springboard's Machine Learning Engineering bootcamp course. This project has exposed me to numerous facets of machine learning and software engineering including data collection, data processing, machine learning modeling, RESTful API design, model deployment, and web design.</p> 
      <br>
      <p class="right_text">My contact information is listed below if you would like to get a hold of me or check out my additional work.</p> 
      <ul class="right_text"> 
        <li><a href="mailto:clemonsjoshua6@gmail.com">Email: clemonsjoshua6@gmail.com</a></li>
        <li><a href="https://github.com/JoshBClemons/">GitHub: /JoshBClemons</a></li>
        <li><a href="https://www.linkedin.com/in/josh-clemons-56b87291/">LinkedIn: /josh-clemons-56b87291</a></li>
      </ul>  
    </div>
    
    <div id="container">
      <video id="myVideo" autoplay="true"></video>
    </div>

    <div class="input_and_prediction" id="input_and_prediction">   
      <div class="input_command">       
        <label for="input_command">Input command</label>
        <input class="input_box" id="input_command"></input>
        <ul> 
          <li><span id="background">b - Save background</span></li>
          <li><span id="reset">r - Reset background</span></li>
          <li><span id="pause">p - Pause / Resume</span></li>
        </ul>  
      </div>     
      <div class="input_gest">
        <label for="gest_select">Input gesture</label>
        <input class="input_box" id="input_gest"></input>
        <ul> 
          <li><span id="closed palm">c - Closed palm</span></li>
          <li><span id="fist">f - Fist</span></li>
          <li><span id="L">l - L</span></li>
          <li><span id="open palm">o - Open palm</span></li>
          <li><span id="thumbs up">t - Thumbs up</span></li>
        </ul>  
      </div>
      <br><br>
      <div class="predicted_gest">
        <h3>Predicted gesture</h3> 
        <h4 id="label">No gesture predicted. Please exit frame of camera and press 'b' to save background and commence predictions.</h4> 
      </div>
    </div>
    
    <script src="//cdnjs.cloudflare.com/ajax/libs/socket.io/3.1.1/socket.io.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <script src="/static/format_elements.js"></script>
    <script src="/static/video_setup.js"></script>
    <script id="gestClassify" src="/static/gestClassify.js" data-source="myVideo" data-mirror="true" data-uploadWidth="1280"></script>
    <script id="login_form" src="/static/login_form.js"></script>
    <script src="/static/input_command.js"></script>
    <script src="/static/input_gesture.js"></script>
    <!-- onmousemove = function(e){console.log("mouse location:", e.clientX, e.clientY)} -->
  </body>
</html>