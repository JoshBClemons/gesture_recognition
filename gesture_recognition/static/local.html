<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Hand Gesture Classifier</title>

    <script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
    <style>
      body {
        font-family: "Franklin Gothic", "ITC Franklin Gothic", Arial, sans-serif;
        background: rgb(255,255,255);
        background: linear-gradient(90deg, rgba(255,255,255,1) 0%, rgba(165,165,165,1) 50%, rgba(255,255,255,1) 100%);
        }
      
      * {
          overflow: hidden; 
          margin: 0;
          outline: 0;
          padding: 0;
      }

      /* Style title */
      .title {
        text-align: center;
        padding: 25px;
      }

      /* Style login area */
      .log_form {
        position: absolute;
        padding-top: 5px;
        padding-left: 5px;
      }
      input[type=username], input[type=password] {
        position: relative;
        width: 50%;
        left: 25%;
        padding: 5px;
        margin: 5px 0;
        display: inline-block;
        border: 1px solid #ccc;
      }
      button[type=submit] {
        position: relative;
        width: 50%;
        left: 25%;
        padding: 5px;
        margin: 5px 5px;
        background-color: #1100ff;
        color: white;
        border: 1px solid #ccc;
        cursor: pointer;
      }
      #login_response {
        position: relative;
        width: 50%;
        left: 25%;
        display: inline-block;
        text-align: center;
      }

      /* Style left and right content */
      div.left_content {
        position: absolute;
        float: left;
        visibility: hidden;
        text-align: left;
      } 
      div.right_content {
        position: absolute;
        float: right;
        visibility: hidden;
        text-align: left;
      }
      .right_text, .left_text {
        padding-right: 40px;
        padding-left: 40px;
        position: relative;
      }
      h2 {
        text-align: center;
      }
      li{
        list-style-position: inside;
        left: 20px;
        position: relative;
      }

      /* Style video streams */
      #container {
        width: 0px;
        height: 0px;
      }
      canvas, video {
        position: absolute;
      }
      video {
        transform: scale(-1, 1);            /*For Firefox (& IE) */
        -webkit-transform: scale(-1, 1);     /*for Chrome & Opera (& Safari) */
      }

      /* Style main interface */     
      .input_and_prediction {
        position: absolute;
        visibility: hidden;
        text-align: center;
        vertical-align: top;
        padding-top: 10px;
        padding-bottom: 10px; 
        height: 185px;
      }
      .input_gest, .input_command {
        display: inline-block;
        text-align: left;
        width: 45%;
        vertical-align: top;
      }
      .input_box {
        width: 130px;
      }
      </style>
  </head>
  <body>
    <h1 class="title" id="title">Gesture Recognition by Josh Clemons</h1>

    <div class="log_form", id="log_form">
      <input id="username" type="username" placeholder="Username or Email" name="uname" required>
      <input id="password" type="password" placeholder="Password" name="psw" required> 
      <button type="submit" id="login_button">Login to start gesture prediction</button>
      <br>
      <p id="login_response"></p>
    </div>

    <div class="left_content" id="left_content">
      <h2>What does this application do?</h2>
      <p class="left_text">This application recognizes hand gestures performed in front of your webcam. Images from your webcam's stream are downloaded, processed, and fed into a convolutional neural network that returns the prediction, prediction confidence, and prediction time below the "Predicted gesture" field.</p>
      <br>
      <p class="left_text">This algorithm predicts the hand gestures listed below.</p>
      <ul class="left_text"> 
        <li>Fist</li>
        <li>L</li>
        <li>Palm</li>
        <li>Thumb</li>
      </ul>  
      <br><br><br>
      <h2 class="left_text">How do I use this application?</h2>
      <p class="left_text">To use this application, follow the steps listed below.</p>
        <ol class="left_text">
          <li>Permit the website access to your computer's webcam</li>
          <li>Login using any username and password. There are no restrictions except neither field can be blank.</li>
          <li>Allow the camera to record for several seconds until the image stabilizes and environment lighting becomes constant</li>
          <li>Completely step out of the camera's field of view and type "b" into the "Input command" field. This saves the current image as the background that will be subtracted from all future images to isolate your hand gesture.</li>
          <li>Perform any one of the listed hand gestures and see how the model performs!</li>
        </ol>  
      <br>
      <p class="left_text">To delete the current background image, type "r" into the "Input command" field.</p> 
      <br>
      <p class="left_text">To pause the application, type "p" into the "Input command" field. Type "p" again to resume.</p> 


    </div>

    <div class="right_content">
      <h2 class="right_text">What does the bottom video show?</h2>
      <p class="right_text">The bottom video shows the processed images that are fed into the neural network. This algorithm is very sensitive to changes in background lighting, so it is important to monitor the bottom video and ensure only your hand appears white while the background remains black. If this is not the case, the algorithm will be fed noisy data and may not return accurate predictions.</p> 
      <br>
      <p class="right_text">If the video is noisy with white and black specks, step out of the camera's field of view and allow lighting to restabilize.</p> 
      <br>
      <p class="right_text">If the video is still noisy, erase the current background image and save a new one.</p> 
      <br><br><br>
      <h2 class="right_text">What data does this application collect?</h2>
      <p class="right_text">This application collects information necessary for model retraining and to inform usage statistics. With this in mind, the application collects your username, password, usage history, and processed binary images like those shown in the bottom video feed.</p> 
      <br>
      <p class="right_text">To view model performance and user activity statistics, click <a href="/stats">here</a>.</p> 
      <br><br><br>
      <h2 class="right_text">Project background and contact information</h2>
      <p class="right_text">I developed and deployed this application to satisfy the capstone project requirement for Springboard's Machine Learning Engineering certification course.</p> 
      <br>
      <p class="right_text">This project has exposed me to numerous facets of machine learning and software engineering including data collection, cleaning, and processing, modeling with neural networks, RESTful API design, model deployment using AWS products, and web design.</p> 
      <br>
      <p class="right_text">My contact information is below if you would like to get a hold of me.</p> 
      <ul class="right_text"> 
        <li><a href="mailto:clemonsjoshua6@gmail.com">Email: clemonsjoshua6@gmail.com</a></li>
        <li><a href="https://github.com/JoshBClemons/">GitHub: /JoshBClemons</a></li>
        <li><a href="https://www.linkedin.com/in/josh-clemons-56b87291/">LinkedIn: /josh-clemons-56b87291</a></li>
      </ul>  
    </div>
    
    <div id="container">
      <video id="myVideo" autoplay="true"></video>
    </div>

    <div class="input_and_prediction" id="input_and_prediction">   
      <div class="input_command">       
        <label for="input_command">Input command</label>
        <input class="input_box" id="input_command"></input>
        <ul> 
          <li><span id="background">b - Save background</span></li>
          <li><span id="reset">r - Reset background</span></li>
          <li><span id="pause">p - Pause / Resume</span></li>
        </ul>  
      </div>     
      <div class="input_gest">
        <label for="gest_select">Input gesture</label>
        <input class="input_box" id="input_gest"></input>
        <ul> 
          <li><span id="fist">f - Fist</span></li>
          <li><span id="L">l - L</span></li>
          <li><span id="palm">p - Palm</span></li>
          <li><span id="thumb">t - Thumb</span></li>
        </ul>  
      </div>
      <br><br>
      <div class="predicted_gest">
        <h3>Predicted gesture</h3> 
        <h4 id="label">No gesture predicted. Please exit camera's field of view then press 'b' to save background and commence predictions.</h4> 
      </div>
    </div>
    
    <script src="//cdnjs.cloudflare.com/ajax/libs/socket.io/3.1.1/socket.io.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <script src="/static/format_elements.js"></script>
    <script src="/static/video_setup.js"></script>
    <script id="classify_gest" src="/static/classify_gest.js" data-source="myVideo" data-mirror="true" data-uploadWidth="1280"></script>
    <script id="login_form" src="/static/login_form.js"></script>
    <script src="/static/input_command.js"></script>
    <script src="/static/input_gesture.js"></script>
    <!-- onmousemove = function(e){console.log("mouse location:", e.clientX, e.clientY)} -->
  </body>
</html>